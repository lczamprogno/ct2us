{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lczamprogno/ct2us/blob/main/CT2US.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-yH0tNkzZ5j"
   },
   "source": [
    "# CT2US\n",
    "\n",
    "This tool is intended to automate the generation of simulated ultrasound image and label pairs from ct volumes (.nii/.nii.gz).\n",
    "\n",
    "CT to Ultrasound simulation with tissue label maps\n",
    "- Developed a modular tool to supplement ultrasound segmentation datasets.\n",
    "- Created a pipeline to process computerized tomography volumes, extract labels for different tissue types and simulate ultrasound slices.\n",
    "- Improved performance, implementing CPU and GPU optimizations.\n",
    "- Created an interface and visualizations, to allow a preview of results, through overlapped slice annotations and sampled point clouds.\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "Intended to be capable of supplementing datasets for ultrasound image labeling.\n",
    "\n",
    "## Expandability\n",
    "Image generation process is very dependant on tissue attenuation, so specialized US renderers would be necessary/ideal to expand this tool to work on other body parts. For this purpose, much of the following code has hence been designed with modularity as a core goal, so that new methods can be added/replaced, as for example the segmentation quality or speed could have a significant impact on overall results. \n",
    "\n",
    "---\n",
    "\n",
    "## Current use:\n",
    "- ![example](https://github.com/lczamprogno/ct2us/blob/main/assets/Full%20Demo.gif)\n",
    "  \n",
    "\n",
    "## Further goals:\n",
    "- code for two alternate optimized segmentation pipelines is still being developed\n",
    "\n",
    "- Improved version of the totalsegmentator nnunet is still WIP. Once that is taken care of, pluging this in the pipeline with the stacked assemble should yield a significant speed up. [ ]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This needs to be run once and then the session needs to be restarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install totalsegmentator numba cupy-cuda12x torchvision xmltodict torchio cucim \"bokeh>=3.1.0\" di gradio pathlib trimesh[easy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pipeline components and ultrasound rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Import pipeline components\n",
    "    from pipeline.dataset import CTDataset\n",
    "    from pipeline.pipeline_config import CT2USPipelineFactory, PipelineConfig\n",
    "except ImportError:\n",
    "    try:\n",
    "        !git clone https://github.com/lczamprogno/ct2us.git\n",
    "\n",
    "        from pipeline.dataset import CTDataset\n",
    "        from pipeline.pipeline_config import CT2USPipelineFactory, PipelineConfig\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xizezx0zbkT"
   },
   "source": [
    "# Classes and methods are gathered here\n",
    "\n",
    "## Run this block\n",
    "\n",
    "IMPORTANT: Acquire a totalsegmentator key (https://backend.totalsegmentator.com/license-academic/) and set google colab secret as shown:\n",
    "\n",
    "![a](https://github.com/lczamprogno/ct2us/blob/main/assets/secret.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not running in Google Colab, using default license key.\n"
     ]
    }
   ],
   "source": [
    "global license\n",
    "try: \n",
    "    from google.colab import userdata\n",
    "    license = userdata.get('license_key')\n",
    "except ImportError as e:\n",
    "    print(\"Not running in Google Colab, using default license key.\")\n",
    "    # If you are running this in a different environment, set your license key here\n",
    "    license = \"\"\n",
    "\n",
    "import os\n",
    "os.environ[\"TS_LICENSE_KEY\"] = license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "E4LlGXlUzJ2h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1+cu124\n",
      "CUDA available: True\n",
      "CUDA version: 12.4\n",
      "CUDA device count: 1\n",
      "CUDA device name: NVIDIA GeForce RTX 4060 Laptop GPU\n",
      "CuPy version: 13.3.0\n",
      "CuPy and cusci loaded successfully\n",
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import PosixPath as pthlib\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from itertools import islice\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Use string for path to avoid PosixPath issues with sys.path\n",
    "this_folder = str(pthlib(\"../CT2US\").resolve())\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(this_folder)\n",
    "ts_cfg_path = pthlib(this_folder).joinpath(\".totalsegmentator\")\n",
    "ts_cfg_path.mkdir(exist_ok=True, parents=True)\n",
    "os.environ[\"TOTALSEG_HOME_DIR\"] = str(ts_cfg_path)\n",
    "\n",
    "# First check CUDA availability and print status\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Will use CPU instead.\")\n",
    "\n",
    "# Now try to import numba and CUDA components\n",
    "from numba import jit, njit, cuda\n",
    "\n",
    "# Try to import cupy if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        import cupyx.scipy.ndimage as cusci\n",
    "        print(f\"CuPy version: {cp.__version__}\")\n",
    "        print(\"CuPy and cusci loaded successfully\")\n",
    "    except ImportError as e:\n",
    "        print(f\"Error loading cupy or cusci even though CUDA is available: {e}\")\n",
    "        cp = None\n",
    "        cusci = None\n",
    "else:\n",
    "    print(\"Not attempting to load CuPy since CUDA is not available\")\n",
    "    cp = None\n",
    "    cusci = None\n",
    "\n",
    "import scipy.ndimage\n",
    "import scipy\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch import device\n",
    "from torch import uint8\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# Set default device based on CUDA availability\n",
    "device = torch.device(\"cuda\", 0) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure and run the CT2US pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base directories\n",
    "img_dir = pthlib(this_folder).joinpath(\"imgs\")\n",
    "label_dir = pthlib(this_folder).joinpath(\"labels\")\n",
    "us_dir = pthlib(this_folder).joinpath(\"us\")\n",
    "gen_dir = pthlib(this_folder).joinpath(\"gen\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(str(img_dir), exist_ok=True)\n",
    "os.makedirs(str(label_dir), exist_ok=True)\n",
    "os.makedirs(str(us_dir), exist_ok=True)\n",
    "os.makedirs(str(gen_dir), exist_ok=True)\n",
    "\n",
    "# Define tissue types mapping for the UI\n",
    "TISSUE_TYPES = {\n",
    "    0: \"Background\",\n",
    "    1: \"Background\",\n",
    "    2: \"Lung\",\n",
    "    3: \"Fat\",\n",
    "    4: \"Vessel\",\n",
    "    5: \"Unused\",\n",
    "    6: \"Kidney\",\n",
    "    7: \"Unused\",\n",
    "    8: \"Muscle\",\n",
    "    9: \"Background\",\n",
    "    10: \"Unused\",\n",
    "    11: \"Liver\",\n",
    "    12: \"Soft Tissue\",\n",
    "    13: \"Bone\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0 (NVIDIA GeForce RTX 4060 Laptop GPU) - Total: 8.00GB, Used: 0.00GB, Free: 8.00GB\n",
      "Using GPU 0 for processing (free memory: 8.00GB)\n",
      "Pipeline configured to use device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Define base factory for the pipeline\n",
    "from pipeline.component_classes import UltrasoundRenderingMethod\n",
    "\n",
    "\n",
    "global _factory\n",
    "\n",
    "_factory = CT2USPipelineFactory()\n",
    "\n",
    "class CACTUSS(UltrasoundRenderingMethod):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.description = \"CACTUSS ultrasound rendering method\"\n",
    "        self.tissue_types = TISSUE_TYPES\n",
    "        \n",
    "    def render(self, data):\n",
    "        # Implement the rendering logic here\n",
    "        raise NotImplementedError(\"Placeholder for CACTUSS rendering logic\")\n",
    "\n",
    "    def name():\n",
    "        return \"CACTUSS\"\n",
    "        \n",
    "_factory.register_rendering_method(CACTUSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ct_images(segmentation_method, rendering_method, step_size=1, **kwargs):\n",
    "    \"\"\"Process CT images using the CT2US pipeline with configurable parameters.\n",
    "    \n",
    "    Args:\n",
    "        ct_images: List of paths to CT images (.nii.gz files)\n",
    "        step_size: Step size for slicing the volume\n",
    "        segmentation_method: Segmentation method to use (\"TotalSegmentator\" or \"TotalSegmentatorFast\")\n",
    "        rendering_method: Rendering method to use (\"lotus\")\n",
    "        **kwargs: Additional configuration parameters to pass to components\n",
    "        \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - List of destination label names\n",
    "        - List of ultrasound images\n",
    "        - List of warped labels\n",
    "        - List of viewable label images\n",
    "        - List of point cloud data\n",
    "        - Dictionary with timing information\n",
    "    \"\"\"\n",
    "    # Initialize dataset\n",
    "    local_dataset = CTDataset(\n",
    "        img_dir=str(img_dir),\n",
    "        resample=None\n",
    "    )\n",
    "    \n",
    "    # Create data loader\n",
    "    ct_dataloader = DataLoader(\n",
    "        local_dataset, \n",
    "        batch_size=1, \n",
    "        collate_fn=local_dataset.collate_fn\n",
    "    )\n",
    "    \n",
    "    # Organize kwargs into component-specific configs\n",
    "    # Extract parameters for each component type\n",
    "    segmentation_config = {}\n",
    "    rendering_config = {}\n",
    "    pointcloud_config = {}\n",
    "    \n",
    "    # Binary operations parameters (used by both segmentation and rendering)\n",
    "    for param in ['binary_dilation_iterations', 'binary_erosion_iterations', 'density_min', 'density_max']:\n",
    "        if param in kwargs:\n",
    "            segmentation_config[param] = kwargs[param]\n",
    "            rendering_config[param] = kwargs[param]\n",
    "    \n",
    "    # Rendering-specific parameters\n",
    "    for param in ['resize_size', 'crop_size']:\n",
    "        if param in kwargs:\n",
    "            rendering_config[param] = kwargs[param]\n",
    "    \n",
    "    # Point cloud-specific parameters (if any)\n",
    "    if 'pointcloud_settings' in kwargs:\n",
    "        pointcloud_config.update(kwargs['pointcloud_settings'])\n",
    "    \n",
    "    # Use string paths for intermediate directory\n",
    "    intermediate_dir = kwargs.get('intermediate_dir', './intermediates')\n",
    "    if hasattr(intermediate_dir, 'startswith') and not intermediate_dir.startswith('/'):\n",
    "        # Convert relative path to absolute if it's a string\n",
    "        intermediate_dir = os.path.join(this_folder, intermediate_dir)\n",
    "    \n",
    "    # Create pipeline configuration\n",
    "    pipeline_config = PipelineConfig(\n",
    "        device='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "        save_intermediates=kwargs.get('save_intermediates', False),\n",
    "        intermediate_dir=intermediate_dir,\n",
    "        segmentation_config=segmentation_config,\n",
    "        rendering_config=rendering_config,\n",
    "        pointcloud_config=pointcloud_config\n",
    "    )\n",
    "    \n",
    "    # Set segmentation method\n",
    "    pipeline_config.set_segmentator(segmentation_method)\n",
    "    \n",
    "    # Set rendering method\n",
    "    pipeline_config.set_renderer(rendering_method)\n",
    "    \n",
    "    pipeline = _factory.create_pipeline(pipeline_config)\n",
    "    \n",
    "    # Process each batch of data\n",
    "    labels = []\n",
    "    us_images = []\n",
    "    warped_labels = []\n",
    "    viewable_labels = []\n",
    "    timing_info = {}\n",
    "    \n",
    "    print(\"Processing data...\")\n",
    "    for data in tqdm.tqdm(ct_dataloader, desc=\"Processing batch\"):\n",
    "        imgs, properties, dest_labels, dest_us = data\n",
    "        \n",
    "        # Process with pipeline\n",
    "        label_imgs, batch_us, batch_warped, batch_viewable, batch_timing = pipeline(\n",
    "            imgs, properties, dest_labels, dest_us, step_size, False\n",
    "        )\n",
    "        \n",
    "        # Store processed data\n",
    "        labels.extend(label_imgs)\n",
    "        us_images.extend(batch_us)\n",
    "        warped_labels.extend(batch_warped)\n",
    "        viewable_labels.extend(batch_viewable)\n",
    "        timing_info.update(batch_timing)\n",
    "    \n",
    "    return labels, us_images, warped_labels, viewable_labels, timing_info, pipeline.pcd_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio UI for interactive use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No need to delete results\n",
      "Pipeline configured to use device: cuda\n",
      "Processing data...\n",
      "SEGMENTATING:\n",
      "CUDA detected: True\n",
      "Cleared CUDA cache\n",
      "Processing image with TotalSegmentator (on device: cuda:0) for task: total...\n",
      "\n",
      "If you use this tool please cite: https://pubs.rsna.org/doi/10.1148/ryai.230024\n",
      "\n",
      "Resampling...\n",
      "  Resampled in 1.60s\n",
      "Predicting part 1 of 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/enter/envs/ct2us/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting part 2 of 5 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/enter/envs/ct2us/lib/python3.10/site-packages/nnunetv2/inference/predict_from_raw_data.py:84: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(join(model_training_output_dir, f'fold_{f}', checkpoint_name),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting part 3 of 5 ...\n",
      "Predicting part 4 of 5 ...\n",
      "Predicting part 5 of 5 ...\n"
     ]
    }
   ],
   "source": [
    "# Set environment for Gradio\n",
    "os.environ[\"GRADIO_ALLOWED_PATHS\"] = this_folder\n",
    "\n",
    "def update_license(x):\n",
    "    global license\n",
    "    license = x\n",
    "\n",
    "with gr.Blocks() as ct_2_us: \n",
    "    # Create state objects for storing data\n",
    "    files = gr.State({})\n",
    "    us_list = gr.State({})\n",
    "    warped_list = gr.State({})\n",
    "    label_list = gr.State({})\n",
    "    pcdb_list = gr.State({})\n",
    "\n",
    "    pcd_method_obj = gr.State({})\n",
    "\n",
    "    img_idx = gr.State(0)\n",
    "    slice_idx = gr.State(0)\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            # Input configuration\n",
    "            gr.Markdown(\"Input Configuration\")\n",
    "            ct_imgs = gr.Files(\n",
    "                file_types=['.nii', '.nii.gz'], \n",
    "                type='filepath', \n",
    "                label=\"Select CT images\", \n",
    "                interactive=True, \n",
    "                file_count='multiple'\n",
    "            )\n",
    "            \n",
    "            step_size = gr.Slider(\n",
    "                label=\"Slicing step interval\", \n",
    "                minimum=1, \n",
    "                maximum=20, \n",
    "                value=1, \n",
    "                step=1, \n",
    "                interactive=True\n",
    "            )   \n",
    "\n",
    "            license_key = gr.Textbox(\n",
    "                label=\"License Key\",\n",
    "                placeholder=\"Enter your totalsegmentator license\",\n",
    "                value=license,\n",
    "                interactive=True\n",
    "            )\n",
    "            \n",
    "\n",
    "            license_key.change(fn=update_license, inputs=[license_key], outputs=None)\n",
    "\n",
    "            # Advanced configuration (accessed via kwargs)\n",
    "            with gr.Accordion(\"Advanced Configuration\", open=False):\n",
    "                binary_dilation_iterations = gr.Slider(\n",
    "                    label=\"Binary Dilation Iterations\", \n",
    "                    minimum=0, \n",
    "                    maximum=5, \n",
    "                    value=2, \n",
    "                    step=1, \n",
    "                    interactive=True\n",
    "                )\n",
    "                \n",
    "                binary_erosion_iterations = gr.Slider(\n",
    "                    label=\"Binary Erosion Iterations\", \n",
    "                    minimum=0, \n",
    "                    maximum=5, \n",
    "                    value=3, \n",
    "                    step=1, \n",
    "                    interactive=True\n",
    "                )\n",
    "                \n",
    "                density_min = gr.Slider(\n",
    "                    label=\"Density Minimum\", \n",
    "                    minimum=-500, \n",
    "                    maximum=0, \n",
    "                    value=-200, \n",
    "                    step=10, \n",
    "                    interactive=True\n",
    "                )\n",
    "                \n",
    "                density_max = gr.Slider(\n",
    "                    label=\"Density Maximum\", \n",
    "                    minimum=0, \n",
    "                    maximum=500, \n",
    "                    value=250, \n",
    "                    step=10, \n",
    "                    interactive=True\n",
    "                )\n",
    "                \n",
    "                resize_size = gr.Slider(\n",
    "                    label=\"Resize Size\", \n",
    "                    minimum=256, \n",
    "                    maximum=512, \n",
    "                    value=380, \n",
    "                    step=8, \n",
    "                    interactive=True\n",
    "                )\n",
    "                \n",
    "                crop_size = gr.Slider(\n",
    "                    label=\"Crop Size\", \n",
    "                    minimum=128, \n",
    "                    maximum=384, \n",
    "                    value=256, \n",
    "                    step=8, \n",
    "                    interactive=True\n",
    "                )\n",
    "                \n",
    "                save_intermediates = gr.Checkbox(\n",
    "                    label=\"Save Intermediate Results\", \n",
    "                    value=False, \n",
    "                    interactive=True\n",
    "                )\n",
    "\n",
    "            with gr.Row():\n",
    "                btn = gr.Button(\"Generate\", variant=\"primary\")\n",
    "                reset = gr.Button(\"Reset\")\n",
    "\n",
    "            # Define reset handler\n",
    "            @gr.on([reset.click], inputs=None, \n",
    "                  outputs=[files, us_list, warped_list, label_list, pcdb_list])\n",
    "            def reset_all():\n",
    "                # Cleanup files\n",
    "                for f in glob.glob(str(label_dir / '*.nii.gz')):\n",
    "                    os.remove(f)\n",
    "                for f in glob.glob(str(img_dir / '*.nii.gz')):\n",
    "                    os.remove(f)\n",
    "                for f in glob.glob(str(gen_dir / '*.glb')):\n",
    "                    os.remove(f)\n",
    "                for f in glob.glob(f\"{str(us_dir)}/*\"):\n",
    "                    shutil.rmtree(f, ignore_errors=True)\n",
    "                try:\n",
    "                    os.remove(f\"{this_folder}/results.zip\")\n",
    "                except:\n",
    "                    print(\"No need to delete results\")\n",
    "                return {}, {}, {}, {}, {}\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    # Sample selection for demo\n",
    "                    sample_in = gr.Dropdown(\n",
    "                        choices=[i+1 for i in range(len(glob.glob(f\"{this_folder}/sample/*.nii.gz\")))], \n",
    "                        label='Amount of samples to randomly select',\n",
    "                        info='Used for demo with no input',\n",
    "                        value=1\n",
    "                    )\n",
    "                    \n",
    "                    # Choose pipeline method\n",
    "                    available_methods = _factory.config.methods[\"segmentation\"].keys()\n",
    "                    available_us = _factory.config.methods[\"rendering\"].keys()\n",
    "\n",
    "                    seg_method = gr.Radio(\n",
    "                        choices=available_methods, \n",
    "                        value=\"TotalSegmentator\", \n",
    "                        label=\"Segmentation method\", \n",
    "                        interactive=True\n",
    "                    )\n",
    "                    \n",
    "                    us_method = gr.Radio(\n",
    "                        choices=available_us, \n",
    "                        value=\"LOTUS\", \n",
    "                        label=\"US rendering method\", \n",
    "                        interactive=True\n",
    "                    )\n",
    "        \n",
    "        with gr.Column(scale=2):\n",
    "            with gr.Tab(label='Pointcloud Settings', visible=False) as pcd_tab:\n",
    "                @gr.render(inputs=[step_size], triggers=[us_list.change])\n",
    "                def pcd_control(step):      \n",
    "                    # Point cloud settings - only show if pipeline is available\n",
    "                    gr.Markdown(\"### Point Cloud Settings\")\n",
    "                    \n",
    "                    # Get tissue types with voxels\n",
    "                    label_counts = _pcd_method.get_label_counts()\n",
    "                    if label_counts and 0 in label_counts:\n",
    "                        available_labels = sorted(label_counts[0].keys())\n",
    "                        \n",
    "                        # Create sliders for each tissue type\n",
    "                        with gr.Row():\n",
    "                            with gr.Column():\n",
    "                                pcd_sliders = []\n",
    "                                for i, label in enumerate(available_labels):\n",
    "                                    if label in TISSUE_TYPES and TISSUE_TYPES[label] != \"Unused\":\n",
    "                                        # Get current point count\n",
    "                                        if i < len(_pcd_method.points_per_label):\n",
    "                                            current_value = _pcd_method.points_per_label[i]\n",
    "                                        else:\n",
    "                                            current_value = 0\n",
    "                                            \n",
    "                                        # Calculate max points\n",
    "                                        max_points = min(label_counts[0].get(label, 0), 400000)\n",
    "                                        \n",
    "                                        # Skip labels with no points\n",
    "                                        if max_points == 0:\n",
    "                                            continue\n",
    "                                        \n",
    "                                        # Create slider\n",
    "                                        slider = gr.Slider(\n",
    "                                            label=f\"{TISSUE_TYPES[label]} Points\",\n",
    "                                            minimum=0,\n",
    "                                            maximum=max_points,\n",
    "                                            value=current_value,\n",
    "                                            step=1000,\n",
    "                                            interactive=True\n",
    "                                        )\n",
    "                                        pcd_sliders.append((label, slider))\n",
    "                                        \n",
    "                                # Create update button\n",
    "                                update_pcd = gr.Button(\"Resample Pointcloud\")\n",
    "                                \n",
    "                                # Handle updates\n",
    "                                def update_point_cloud(x, y, *slider_values):\n",
    "                                    # Get current points per label\n",
    "                                    new_counts = _pcd_method.points_per_label.copy()\n",
    "                                    \n",
    "                                    # Update with slider values\n",
    "                                    for (label, _), value in zip(pcd_sliders, slider_values):\n",
    "                                        if label < len(new_counts):\n",
    "                                            new_counts[label] = int(value)\n",
    "                                        \n",
    "                                    # Update point cloud\n",
    "                                    _pcd_method.update_points_per_label(new_counts)\n",
    "\n",
    "                                    # Re-export\n",
    "                                    pcdb_new = _pcd_method.sample(x)\n",
    "                                    \n",
    "                                    try:\n",
    "                                        # Make sure to use a safe value for the slice index\n",
    "                                        safe_slice = min(int(y * step), pcdb_new[2][2]-1) if len(pcdb_new) >= 3 and hasattr(pcdb_new[2], \"__len__\") and len(pcdb_new[2]) >= 3 else 0\n",
    "                                        _pcd_method.add_axis_pcd(pcdb_new, safe_slice).export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error creating axis point cloud: {e}\")\n",
    "                                        # Create a fallback point cloud if there's an error\n",
    "                                        import trimesh as tri\n",
    "                                        fallback_pcd = tri.PointCloud([[0, 0, 0]], colors=[[255, 255, 255, 255]])\n",
    "                                        fallback_pcd.export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                                    \n",
    "                                    # Return the path to the new point cloud\n",
    "                                    return pcdb_new\n",
    "                                \n",
    "                                # Connect button to handler\n",
    "                                if pcd_sliders:\n",
    "                                    update_pcd.click(\n",
    "                                        fn=update_point_cloud,\n",
    "                                        inputs=[img_idx, slice_idx] + [s[1] for s in pcd_sliders],\n",
    "                                        outputs=pcdb_list\n",
    "                                    )\n",
    "                                \n",
    "\n",
    "            with gr.Tab(label='Preview'):\n",
    "                note = gr.Markdown(value=\"Generate US images first through the input tab\")\n",
    "\n",
    "                # Dynamic UI based on available data\n",
    "                @gr.render(inputs=[files, us_list, warped_list, label_list, step_size], \n",
    "                         triggers=[us_list.change])\n",
    "                def dynamic(fl, us, warped, ll, step):       \n",
    "                    with gr.Column():\n",
    "                        if len(us) > 0:\n",
    "                            # Image selection\n",
    "                            dropdown = gr.Dropdown(\n",
    "                                choices=[(f, n) for n, f in fl.items()], \n",
    "                                label='Select image to preview', \n",
    "                                value=0\n",
    "                            )\n",
    "                            \n",
    "                            # Slice selection\n",
    "                            slider = gr.Slider(\n",
    "                                minimum=0, \n",
    "                                maximum=len(warped[0]) - 1, \n",
    "                                step=step, \n",
    "                                label='Slice selection', \n",
    "                                value=0\n",
    "                            )\n",
    "                            \n",
    "                            # Identity function for state updates\n",
    "                            iden = lambda x: x\n",
    "\n",
    "                            slider.release(fn=iden, inputs=[slider], outputs=[slice_idx])\n",
    "                            dropdown.select(fn=iden, inputs=[dropdown], outputs=[img_idx])\n",
    "\n",
    "                            # Results display\n",
    "                            with gr.Column():\n",
    "                                # Top row: US and label images\n",
    "                                with gr.Row():\n",
    "                                    base = gr.Image(\n",
    "                                        label='US slice',\n",
    "                                        value=np.asarray(us[img_idx.value][slice_idx.value], dtype=np.float32) if len(us) > 0 and len(us[0]) > 0 else np.zeros((256, 256), dtype=np.float32),\n",
    "                                        height=300\n",
    "                                    )\n",
    "                                    \n",
    "                                    label_preview = gr.Image(\n",
    "                                        label='Label slice',\n",
    "                                        value=ll[img_idx.value][slice_idx.value] if len(ll) > 0 else None,\n",
    "                                        type='pil',\n",
    "                                        height=300\n",
    "                                    )\n",
    "                                \n",
    "                                # Bottom row: Annotation and 3D view\n",
    "                                with gr.Row():\n",
    "                                    comp = gr.AnnotatedImage(\n",
    "                                        value=(us[img_idx.value][slice_idx.value], warped[img_idx.value][slice_idx.value]),\n",
    "                                        height=300\n",
    "                                    )\n",
    "                                    \n",
    "                                    volume_preview = gr.Model3D(\n",
    "                                        clear_color=(0, 0, 0, 1), \n",
    "                                        label=\"Label map view\", \n",
    "                                        value=str(gen_dir / \"current_pcd.glb\") if os.path.exists(str(gen_dir / \"current_pcd.glb\")) else None, \n",
    "                                        height=300\n",
    "                                    )\n",
    "                                    \n",
    "                                pcdb_list.change(fn=lambda : str(gen_dir / \"current_pcd.glb\"), outputs=volume_preview)\n",
    "                                    \n",
    "                                # Update function for image/slice selection\n",
    "                                def route(x, y, pcdb):\n",
    "                                        new_y = y if y < len(us[x]) else 0\n",
    "                                    \n",
    "                                        b = us[x][new_y]\n",
    "                                        w = warped[x][new_y]\n",
    "                                        l = ll[x][new_y]\n",
    "                                        \n",
    "                                        # adjust current slice highlighted\n",
    "                                        pcdb = _pcd_method.sample(x)\n",
    "\n",
    "                                        # Make sure to use a safe value for the slice index\n",
    "                                        safe_slice = min(int(y * step), pcdb[2][2]-1) if len(pcdb) >= 3 and hasattr(pcdb[2], \"__len__\") and len(pcdb[2]) >= 3 else 0\n",
    "                                        _pcd_method.add_axis_pcd(pcdb, safe_slice).export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                                        \n",
    "                                        # Calculate new slider value and ensure it's in range\n",
    "                                        new_slider = gr.Slider(\n",
    "                                            minimum=0, \n",
    "                                            maximum=len(warped[x]) - 1, \n",
    "                                            step=step, \n",
    "                                            label='Slice selection', \n",
    "                                            value=new_y\n",
    "                                        )\n",
    "                                        \n",
    "                                        # Return updated UI components \n",
    "                                        return (b, w), b, l, str(gen_dir / \"current_pcd.glb\"), new_y, new_slider, pcdb\n",
    "                                    # except Exception as e:\n",
    "                                    #     print(f\"Error in route function: {e}\")\n",
    "                                    #     # Return default values on error\n",
    "                                    #     empty_img = np.zeros((256, 256), dtype=np.float32)\n",
    "                                    #     return (empty_img, []), empty_img, None, None, 0, slider\n",
    "                                    \n",
    "                                def route_y(x, y, pcdb):\n",
    "                                    # try:\n",
    "                                        b = us[x][y]\n",
    "                                        w = warped[x][y]\n",
    "                                        l = ll[x][y]\n",
    "                                        \n",
    "                                        # adjust current slice highlighted\n",
    "                                        try:\n",
    "                                            # Make sure to use a safe value for the slice index\n",
    "                                            safe_slice = min(int(y * step), pcdb[2][2]-1) if len(pcdb) >= 3 and hasattr(pcdb[2], \"__len__\") and len(pcdb[2]) >= 3 else 0\n",
    "                                            _pcd_method.add_axis_pcd(pcdb, safe_slice).export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"Error creating axis point cloud: {e}\")\n",
    "                                            # Create a fallback point cloud if there's an error\n",
    "                                            import trimesh as tri\n",
    "                                            fallback_pcd = tri.PointCloud([[0, 0, 0]], colors=[[255, 255, 255, 255]])\n",
    "                                            fallback_pcd.export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                                        \n",
    "                                        # Return updated UI components \n",
    "                                        return (b, w), b, l, str(gen_dir / \"current_pcd.glb\")\n",
    "                                    # except Exception as e:\n",
    "                                    #     print(f\"Error in route function: {e}\")\n",
    "                                    #     # Return default values on error\n",
    "                                    #     empty_img = np.zeros((256, 256), dtype=np.float32)\n",
    "                                    #     return (empty_img, []), empty_img, None, None\n",
    "                                \n",
    "                                # Connect route function to UI events\n",
    "                                gr.on(\n",
    "                                    triggers=[img_idx.change],\n",
    "                                    fn=route,\n",
    "                                    inputs=[img_idx, slice_idx, pcdb_list],\n",
    "                                    outputs=[comp, base, label_preview, volume_preview, slice_idx, slider, pcdb_list]\n",
    "                                )\n",
    "                                gr.on(\n",
    "                                    triggers=[slice_idx.change],\n",
    "                                    fn=route_y,\n",
    "                                    inputs=[img_idx, slice_idx, pcdb_list],\n",
    "                                    outputs=[comp, base, label_preview, volume_preview]\n",
    "                                )\n",
    "                            \n",
    "            with gr.Tab(label='Download'):\n",
    "                download = gr.DownloadButton(label=\"\", visible=False)\n",
    "                \n",
    "                # Dynamic UI for download options\n",
    "                @gr.render(inputs=[files, us_list, warped_list, label_list, pcdb_list, step_size], \n",
    "                         triggers=[us_list.change])\n",
    "                def dynamic(fl, us, warped, ll, pcdb, step):\n",
    "                    descr = gr.Markdown(label=\"This can be used to adjust contents of results.zip\")\n",
    "                    configs = gr.CheckboxGroup(\n",
    "                        choices=[\"Save labels\", \"Save US images\"], \n",
    "                        value=[\"Save labels\", \"Save US images\"], \n",
    "                        label=\"Options\", \n",
    "                        interactive=True\n",
    "                    )\n",
    "                    filename_in = gr.Textbox(label=\"Filename for result zip\", value=\"results\")\n",
    "\n",
    "                    r = []\n",
    "                    r.append(glob.glob(str(label_dir / '*.nii.gz')))\n",
    "                    r.append(glob.glob(str(us_dir / '**/*.png')))\n",
    "\n",
    "                    rezip = gr.Button(\"Reassemble results.zip\")\n",
    "\n",
    "                    @gr.on(rezip.click, inputs=[configs, filename_in], outputs=[download, descr])\n",
    "                    def rezip_files(save_configs, name, r=r):\n",
    "                        with ZipFile(f\"{this_folder}/results.zip\", 'w') as zipObj:\n",
    "                            # Save labels if selected\n",
    "                            if \"Save labels\" in save_configs:\n",
    "                                for f in r[0]:\n",
    "                                    zipObj.write(f, os.path.relpath(f, this_folder))\n",
    "                                    # Don't delete labels until we're done\n",
    "                            \n",
    "                            # Save US images if selected\n",
    "                            if \"Save US images\" in save_configs:\n",
    "                                for f in r[1]:\n",
    "                                    zipObj.write(f, os.path.relpath(f, this_folder))\n",
    "                            \n",
    "                            # Clean up if requested\n",
    "                            if \"Clean up after export\" in save_configs:\n",
    "                                for f in r[0]:\n",
    "                                    os.remove(f)\n",
    "                                for f in glob.glob(f\"{str(us_dir)}/*\"):\n",
    "                                    shutil.rmtree(f, ignore_errors=True)\n",
    "\n",
    "                        return f\"{this_folder}/{name}.zip\", \"Results have been rezipped\"\n",
    "\n",
    "                def start(ct, step, method, method_us, fl_s, us_s, warped_s, ll_s, pcdb_s, nr_samples,\n",
    "                         binary_dilation_iters, binary_erosion_iters, dens_min, dens_max, resize, crop, save_int,\n",
    "                         progress=gr.Progress(track_tqdm=True)):                    \n",
    "                    # Sample if no input\n",
    "                    if not ct:\n",
    "                        ct = glob.glob(f\"{this_folder}/sample/*.nii.gz\")\n",
    "                        ct = [f for f in ct]\n",
    "\n",
    "                    # Random sample if needed\n",
    "                    if len(ct) > nr_samples:\n",
    "                        ct = random.sample(ct, k=nr_samples)\n",
    "\n",
    "                    # Copy files to working directory\n",
    "                    for f in ct:\n",
    "                        shutil.copyfile(f, str(img_dir / os.path.basename(f)))\n",
    "                    \n",
    "                    # Organize parameters into component-specific configs\n",
    "                    # Common parameters for different components\n",
    "                    segmentation_config = {\n",
    "                        'binary_dilation_iterations': binary_dilation_iters,\n",
    "                        'binary_erosion_iterations': binary_erosion_iters,\n",
    "                        'density_min': dens_min,\n",
    "                        'density_max': dens_max\n",
    "                    }\n",
    "                    \n",
    "                    rendering_config = {\n",
    "                        'binary_dilation_iterations': binary_dilation_iters,\n",
    "                        'binary_erosion_iterations': binary_erosion_iters,\n",
    "                        'density_min': dens_min,\n",
    "                        'density_max': dens_max,\n",
    "                        'resize_size': resize,\n",
    "                        'crop_size': crop\n",
    "                    }\n",
    "                    \n",
    "                    # Process images using the pipeline with all configuration parameters\n",
    "                    labels, us_images, warped_labels, viewable_labels, timing_info, sampler = process_ct_images(\n",
    "                        ct_images=ct,\n",
    "                        step_size=step,\n",
    "                        segmentation_method=method,\n",
    "                        rendering_method=method_us,\n",
    "                        save_intermediates=save_int,\n",
    "                        segmentation_config=segmentation_config,\n",
    "                        rendering_config=rendering_config\n",
    "                    )\n",
    "                    \n",
    "                    # Get point cloud sampler for later adjustment\n",
    "                    global _pcd_method\n",
    "                    _pcd_method = sampler\n",
    "                        \n",
    "                    # Update state\n",
    "                    fl_s.update(enumerate(labels))\n",
    "                    us_s.update(enumerate(us_images))\n",
    "                    ll_s.update(enumerate(viewable_labels))\n",
    "                    warped_s.update(enumerate(warped_labels))\n",
    "                    \n",
    "                    # Sample point clouds and save initial 3D view\n",
    "                    pcdb_s = _pcd_method.sample(0)\n",
    "                    \n",
    "                    try:\n",
    "                        # Create initial view with slice 0\n",
    "                        _pcd_method.add_axis_pcd(pcdb_s, 0).export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating initial point cloud: {e}\")\n",
    "                        # Create a fallback point cloud if there's an error\n",
    "                        import trimesh as tri\n",
    "                        fallback_pcd = tri.PointCloud([[0, 0, 0]], colors=[[255, 255, 255, 255]])\n",
    "                        fallback_pcd.export(str(gen_dir / \"current_pcd.glb\"))\n",
    "\n",
    "                    # Return downloadable zip and updated states\n",
    "                    return (\n",
    "                        gr.DownloadButton(label=\"Download results as zip\", visible=True, value=f\"{this_folder}/results.zip\"), \n",
    "                        fl_s, \n",
    "                        us_s, \n",
    "                        warped_s, \n",
    "                        ll_s, \n",
    "                        pcdb_s,\n",
    "                        gr.Markdown(value=\"Processing complete!\", height=30)\n",
    "                    )\n",
    "                \n",
    "                def finalize(x):\n",
    "                    return gr.Markdown(label=\"\", value=\"\", height=0, visible=False), gr.Tab(label=\"Pointcloud Settings\", visible=True)\n",
    "                                \n",
    "                # Connect generate button\n",
    "                btn.click(\n",
    "                    fn=reset_all,\n",
    "                    inputs=None, \n",
    "                    outputs=[files, us_list, warped_list, label_list, pcdb_list]\n",
    "                ).success(\n",
    "                    fn=lambda x: gr.Markdown(label=\"Status\", value=\"Processing...\", height=80), \n",
    "                    inputs=btn, \n",
    "                    outputs=note\n",
    "                ).success(\n",
    "                    fn=start, \n",
    "                    inputs=[\n",
    "                        ct_imgs, step_size, seg_method, us_method, files, us_list, warped_list, \n",
    "                        label_list, pcdb_list, sample_in, binary_dilation_iterations, \n",
    "                        binary_erosion_iterations, density_min, density_max, resize_size, \n",
    "                        crop_size, save_intermediates\n",
    "                    ],\n",
    "                    outputs=[download, files, us_list, warped_list, label_list, pcdb_list, note]\n",
    "                ).success(\n",
    "                    fn=finalize,\n",
    "                    inputs=btn,\n",
    "                    outputs=[note, pcd_tab]\n",
    "                )                           \n",
    "\n",
    "# Launch the Gradio app\n",
    "ct_2_us.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ct2us",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
