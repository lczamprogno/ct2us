{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/lczamprogno/ct2us/blob/main/CT2US.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-yH0tNkzZ5j"
   },
   "source": [
    "# CT2US\n",
    "\n",
    "This tool is intended to automate the generation of simulated ultrasound image and label pairs from ct volumes (.nii/.nii.gz).\n",
    "\n",
    "CT to Ultrasound simulation with tissue label maps\n",
    "- Developed a modular tool to supplement ultrasound segmentation datasets.\n",
    "- Created a pipeline to process computerized tomography volumes, extract labels for different tissue types and simulate ultrasound slices.\n",
    "- Improved performance, implementing CPU and GPU optimizations.\n",
    "- Created an interface and visualizations, to allow a preview of results, through overlapped slice annotations and sampled point clouds.\n",
    "\n",
    "---\n",
    "\n",
    "### Purpose\n",
    "Intended to be capable of supplementing datasets for ultrasound image labeling.\n",
    "\n",
    "## Expandability\n",
    "Image generation process is very dependant on tissue attenuation, so specialized US renderers would be necessary/ideal to expand this tool to work on other body parts. For this purpose, much of the following code has hence been designed with modularity as a core goal, so that new methods can be added/replaced, as for example the segmentation quality or speed could have a significant impact on overall results.\n",
    "\n",
    "---\n",
    "\n",
    "## Current use:\n",
    "- ![example](https://drive.google.com/uc?export=view&id=16LZ1vCoQ48w1Xn8lBJ1ZrsRe0ngEgbjB)\n",
    "  \n",
    "\n",
    "## Further goals:\n",
    "- code for two alternate optimized segmentation pipelines is still being developed\n",
    "\n",
    "- Improved version of the totalsegmentator nnunet is still WIP. Once that is taken care of, pluging this in the pipeline with the stacked assemble should yield a significant speed up. [ ]\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UtyfljaMvwKO"
   },
   "source": [
    "This needs to be run once and then the session needs to be restarted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PjKF53ocvwKP"
   },
   "outputs": [],
   "source": [
    "%pip install totalsegmentator numba cupy-cuda12x torchvision xmltodict torchio cucim \"bokeh>=3.1.0\" di gradio pathlib trimesh[easy] batchgenerators\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LebJRtbnvwKP"
   },
   "source": [
    "# Import pipeline components and ultrasound rendering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j8djTO3ZvwKQ"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Import pipeline components\n",
    "    from pipeline.dataset import CTDataset\n",
    "    from pipeline.pipeline_config import CT2USPipelineFactory, PipelineConfig\n",
    "except ImportError:\n",
    "    try:\n",
    "        from ct2us.pipeline.dataset import CTDataset\n",
    "        from ct2us.pipeline.pipeline_config import CT2USPipelineFactory, PipelineConfig\n",
    "\n",
    "    except Exception as e:\n",
    "        !git clone https://github.com/lczamprogno/ct2us.git\n",
    "\n",
    "        from ct2us.pipeline.dataset import CTDataset\n",
    "        from ct2us.pipeline.pipeline_config import CT2USPipelineFactory, PipelineConfig\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4xizezx0zbkT"
   },
   "source": [
    "# Classes and methods are gathered here\n",
    "\n",
    "## Run this block\n",
    "\n",
    "IMPORTANT: Acquire a totalsegmentator key (https://backend.totalsegmentator.com/license-academic/) and set google colab secret as shown:\n",
    "\n",
    "![a](https://drive.google.com/uc?export=view&id=1dTIOm2P2soqp3COY0XCPTHZrRKalkBYN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bBMVtl8PvwKR"
   },
   "outputs": [],
   "source": [
    "global license\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    license = userdata.get('license_key')\n",
    "except ImportError as e:\n",
    "    print(\"Not running in Google Colab, using default license key.\")\n",
    "    # If you are running this in a different environment, set your license key here\n",
    "    license = \"\"\n",
    "\n",
    "# Make sure license is set in environment\n",
    "import os\n",
    "if license:\n",
    "    os.environ[\"TS_LICENSE_KEY\"] = license\n",
    "    print(f\"Set TS_LICENSE_KEY in environment\")\n",
    "    \n",
    "    # Verify the license is set\n",
    "    if \"TS_LICENSE_KEY\" in os.environ and os.environ[\"TS_LICENSE_KEY\"]:\n",
    "        print(f\"Confirmed TS_LICENSE_KEY is set in environment\")\n",
    "    else:\n",
    "        print(f\"Warning: Failed to set TS_LICENSE_KEY in environment\")\n",
    "        \n",
    "    # Also try to set it in totalsegmentator directly if available\n",
    "    try:\n",
    "        import totalsegmentator.python_api as ts\n",
    "        ts.set_license_number(license)\n",
    "        print(f\"Set license directly in TotalSegmentator API\")\n",
    "    except ImportError:\n",
    "        print(f\"Note: TotalSegmentator not yet imported, license will be set during initialization\")\n",
    "else:\n",
    "    print(f\"Warning: No license key available to set in environment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E4LlGXlUzJ2h"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "from pathlib import PosixPath as pthlib\n",
    "from zipfile import ZipFile\n",
    "import random\n",
    "\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "from itertools import islice\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Use string for path to avoid PosixPath issues with sys.path\n",
    "this_folder = str(pthlib(\"../CT2US\").resolve())\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.append(this_folder)\n",
    "ts_cfg_path = pthlib(this_folder).joinpath(\".totalsegmentator\")\n",
    "ts_cfg_path.mkdir(exist_ok=True, parents=True)\n",
    "os.environ[\"TOTALSEG_HOME_DIR\"] = str(ts_cfg_path)\n",
    "\n",
    "# First check CUDA availability and print status\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "\n",
    "try:\n",
    "    cuda_available = torch.cuda.is_available()\n",
    "    print(f\"CUDA available: {cuda_available}\")\n",
    "    if cuda_available:\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"CUDA device count: {torch.cuda.device_count()}\")\n",
    "        print(f\"CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "    else:\n",
    "        print(\"CUDA is not available. Will use CPU instead.\")\n",
    "        # If CUDA is not available, explicitly disable it\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "        os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "except Exception as e:\n",
    "    print(f\"Error checking CUDA availability: {e}\")\n",
    "    print(\"This appears to be a CPU-only environment. Using CPU mode.\")\n",
    "    cuda_available = False\n",
    "    # Set environment variables to prevent CUDA/GPU usage\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "    os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "\n",
    "# Try to import numba and CUDA components - handle failures gracefully\n",
    "try:\n",
    "    from numba import jit, njit\n",
    "    print(\"Numba loaded successfully\")\n",
    "    \n",
    "    # Only try to import CUDA components if CUDA is available\n",
    "    if cuda_available:\n",
    "        try:\n",
    "            from numba import cuda as numba_cuda\n",
    "            print(\"Numba CUDA loaded successfully\")\n",
    "        except ImportError as e:\n",
    "            print(f\"Error loading Numba CUDA: {e}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Error loading Numba: {e}\")\n",
    "\n",
    "# Try to import cupy if CUDA is available\n",
    "if cuda_available:\n",
    "    try:\n",
    "        import cupy as cp\n",
    "        import cupyx.scipy.ndimage as cusci\n",
    "        print(f\"CuPy version: {cp.__version__}\")\n",
    "        print(\"CuPy and cusci loaded successfully\")\n",
    "    except ImportError as e:\n",
    "        print(f\"Error loading cupy or cusci even though CUDA is available: {e}\")\n",
    "        cp = None\n",
    "        cusci = None\n",
    "else:\n",
    "    print(\"Not attempting to load CuPy since CUDA is not available\")\n",
    "    cp = None\n",
    "    cusci = None\n",
    "\n",
    "import scipy.ndimage\n",
    "import scipy\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch import device\n",
    "from torch import uint8\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# Set default device based on CUDA availability\n",
    "if cuda_available:\n",
    "    device = torch.device(\"cuda\", 0)\n",
    "    print(f\"Using device: {device}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(f\"Using device: {device} (CPU-only mode)\")\n",
    "\n",
    "# Set default device for PyTorch operations\n",
    "try:\n",
    "    torch.set_default_device(device)\n",
    "except Exception as e:\n",
    "    print(f\"Error setting default device: {e}\")\n",
    "    # Fallback for older PyTorch versions\n",
    "    if hasattr(torch, 'set_default_tensor_type'):\n",
    "        if device.type == 'cuda':\n",
    "            torch.set_default_tensor_type('torch.cuda.FloatTensor')\n",
    "        else:\n",
    "            torch.set_default_tensor_type('torch.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "__rBkRBEvwKS"
   },
   "source": [
    "# Configure and run the CT2US pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5OesF5fTvwKT"
   },
   "outputs": [],
   "source": [
    "# Define base directories\n",
    "img_dir = pthlib(this_folder).joinpath(\"imgs\")\n",
    "label_dir = pthlib(this_folder).joinpath(\"labels\")\n",
    "us_dir = pthlib(this_folder).joinpath(\"us\")\n",
    "gen_dir = pthlib(this_folder).joinpath(\"gen\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(str(img_dir), exist_ok=True)\n",
    "os.makedirs(str(label_dir), exist_ok=True)\n",
    "os.makedirs(str(us_dir), exist_ok=True)\n",
    "os.makedirs(str(gen_dir), exist_ok=True)\n",
    "\n",
    "# Define tissue types mapping for the UI\n",
    "TISSUE_TYPES = {\n",
    "    0: \"Background\",\n",
    "    1: \"Background\",\n",
    "    2: \"Lung\",\n",
    "    3: \"Fat\",\n",
    "    4: \"Vessel\",\n",
    "    5: \"Unused\",\n",
    "    6: \"Kidney\",\n",
    "    7: \"Unused\",\n",
    "    8: \"Muscle\",\n",
    "    9: \"Background\",\n",
    "    10: \"Unused\",\n",
    "    11: \"Liver\",\n",
    "    12: \"Soft Tissue\",\n",
    "    13: \"Bone\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6jpK-mFBvwKU"
   },
   "outputs": [],
   "source": [
    "# Define base factory for the pipeline\n",
    "try:\n",
    "    from pipeline.component_classes import SegmentationMethod\n",
    "    from pipeline.component_classes import UltrasoundRenderingMethod\n",
    "    from pipeline.component_classes import OptimizedLotusRenderer\n",
    "except ImportError:\n",
    "    from ct2us.pipeline.component_classes import OptimizedLotusRenderer\n",
    "    from ct2us.pipeline.component_classes import SegmentationMethod\n",
    "    from ct2us.pipeline.component_classes import UltrasoundRenderingMethod\n",
    "\n",
    "\n",
    "global _factory\n",
    "\n",
    "_factory = CT2USPipelineFactory()\n",
    "\n",
    "class CACTUSS(UltrasoundRenderingMethod):\n",
    "    def __init__(self, kwargs):\n",
    "        super().__init__(kwargs)\n",
    "        self.description = \"CACTUSS ultrasound rendering method\"\n",
    "        self.tissue_types = TISSUE_TYPES\n",
    "\n",
    "    def render(self, data):\n",
    "        # Implement the rendering logic here\n",
    "        raise NotImplementedError(\"Placeholder for CACTUSS rendering logic\")\n",
    "\n",
    "    def name():\n",
    "        return \"CACTUSS\"\n",
    "\n",
    "class PrelabeledBypass(SegmentationMethod):\n",
    "    def __init__(self, kwargs):\n",
    "        super().__init__(kwargs)\n",
    "        self.description = \"Used to bypass segmentation and use pre-labeled data\"\n",
    "\n",
    "    def segment(self, \n",
    "                imgs: list[np.ndarray],\n",
    "                properties: list[dict],\n",
    "                task: str,\n",
    "                resamp_thr: int):\n",
    "\n",
    "        ret = []\n",
    "        for img in imgs:\n",
    "            # Convert to uint8 and return\n",
    "            img = np.asarray(img.dataobj, dtype=np.uint8)\n",
    "            if self.m == cp:\n",
    "                img = self.m.asarray(img)\n",
    "            ret.append(img)\n",
    "        return ret\n",
    "\n",
    "    def assemble(self,\n",
    "                task: str,\n",
    "                segs: list[np.ndarray],\n",
    "                bases: list[np.ndarray],\n",
    "                prev: list[np.ndarray]):\n",
    "        return segs\n",
    "    \n",
    "    def tasks(self):\n",
    "        return [\"bypass\"]\n",
    "\n",
    "    def name():\n",
    "        return \"PrelabeledBypass\"\n",
    "\n",
    "_factory.register_rendering_method(CACTUSS)\n",
    "_factory.register_segmentation_method(PrelabeledBypass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LebKLnLbvwKU"
   },
   "outputs": [],
   "source": [
    "def process_ct_images(segmentation_method, rendering_method, step_size=1, **kwargs):\n",
    "    \"\"\"Process CT images using the CT2US pipeline with configurable parameters.\n",
    "\n",
    "    Args:\n",
    "        ct_images: List of paths to CT images (.nii.gz files)\n",
    "        step_size: Step size for slicing the volume\n",
    "        segmentation_method: Segmentation method to use (\"TotalSegmentator\" or \"TotalSegmentatorFast\")\n",
    "        rendering_method: Rendering method to use (\"lotus\")\n",
    "        **kwargs: Additional configuration parameters to pass to components\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - List of destination label names\n",
    "        - List of ultrasound images\n",
    "        - List of warped labels\n",
    "        - List of viewable label images\n",
    "        - Dictionary with timing information\n",
    "    \"\"\"\n",
    "    # Initialize dataset\n",
    "    local_dataset = CTDataset(\n",
    "        img_dir=str(img_dir),\n",
    "        resample=None,\n",
    "        force_cpu=kwargs.get('force_cpu', False)  # Pass force_cpu to dataset\n",
    "    )\n",
    "\n",
    "    if 'render_interp' in kwargs:\n",
    "        segmentation_config['render_interp'] = kwargs.get(kwargs['render_interp'], True)\n",
    "\n",
    "    # Create data loader\n",
    "    ct_dataloader = DataLoader(\n",
    "        local_dataset,\n",
    "        batch_size=1,\n",
    "        collate_fn=local_dataset.collate_fn\n",
    "    )\n",
    "\n",
    "    # Organize kwargs into component-specific configs\n",
    "    # Extract parameters for each component type\n",
    "    segmentation_config = {}\n",
    "    rendering_config = {}\n",
    "    pointcloud_config = {}\n",
    "\n",
    "    # Binary operations parameters (used by both segmentation and rendering)\n",
    "    for param in ['binary_dilation_iterations', 'binary_erosion_iterations', 'density_min', 'density_max']:\n",
    "        if param in kwargs:\n",
    "            segmentation_config[param] = kwargs[param]\n",
    "            rendering_config[param] = kwargs[param]\n",
    "    \n",
    "    # Segmentation-specific parameters\n",
    "    for param in ['use_roi', 'force_cpu', 'fast']:\n",
    "        if param in kwargs:\n",
    "            segmentation_config[param] = kwargs[param]\n",
    "            if param == 'force_cpu' and kwargs[param]:\n",
    "                print(\"Using CPU for all computations\")\n",
    "\n",
    "    # Rendering-specific parameters\n",
    "    for param in ['resize_size', 'crop_size']:\n",
    "        if param in kwargs:\n",
    "            rendering_config[param] = kwargs[param]\n",
    "\n",
    "    # Point cloud-specific parameters (if any)\n",
    "    if 'pointcloud_settings' in kwargs:\n",
    "        pointcloud_config.update(kwargs['pointcloud_settings'])\n",
    "\n",
    "    # Use string paths for intermediate directory\n",
    "    intermediate_dir = kwargs.get('intermediate_dir', './intermediates')\n",
    "    if hasattr(intermediate_dir, 'startswith') and not intermediate_dir.startswith('/'):\n",
    "        # Convert relative path to absolute if it's a string\n",
    "        intermediate_dir = os.path.join(this_folder, intermediate_dir)\n",
    "\n",
    "    # Device selection - note that force_cpu overrides CUDA availability\n",
    "    force_cpu = kwargs.get('force_cpu', False)\n",
    "    device_str = 'cpu' if force_cpu else ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Ensure force_cpu is consistently set in all config dictionaries\n",
    "    if force_cpu:\n",
    "        segmentation_config['force_cpu'] = True\n",
    "        rendering_config['force_cpu'] = True\n",
    "        pointcloud_config['force_cpu'] = True\n",
    "    \n",
    "\n",
    "    # Create pipeline configuration\n",
    "    _factory.config.configure(\n",
    "        device=device_str,\n",
    "        force_cpu=force_cpu,  # Explicitly pass the force_cpu flag to PipelineConfig\n",
    "        save_intermediates=kwargs.get('save_intermediates', False),\n",
    "        intermediate_dir=intermediate_dir,\n",
    "        segmentation_config=segmentation_config,\n",
    "        rendering_config=rendering_config,\n",
    "        pointcloud_config=pointcloud_config\n",
    "    )\n",
    "\n",
    "    # Set segmentation method\n",
    "    _factory.config.set_segmentator(segmentation_method)\n",
    "\n",
    "    # Set rendering method\n",
    "    _factory.config.set_renderer(rendering_method)\n",
    "    \n",
    "    pipeline = _factory.create_pipeline()\n",
    "\n",
    "    # Process each batch of data\n",
    "    labels = []\n",
    "    us_images = []\n",
    "    warped_labels = []\n",
    "    viewable_labels = []\n",
    "    timing_info = {}\n",
    "\n",
    "    print(\"Processing data...\")\n",
    "    for data in tqdm.tqdm(ct_dataloader, desc=\"Processing batch\"):\n",
    "        imgs, properties, dest_labels, dest_us = data\n",
    "\n",
    "        # Process with pipeline\n",
    "        label_imgs, batch_us, batch_warped, batch_viewable, batch_timing = pipeline(\n",
    "            imgs, properties, dest_labels, dest_us, step_size, True\n",
    "        )\n",
    "\n",
    "        # Store processed data\n",
    "        labels.extend(label_imgs)\n",
    "        us_images.extend(batch_us)\n",
    "        warped_labels.extend(batch_warped)\n",
    "        viewable_labels.extend(batch_viewable)\n",
    "        timing_info.update(batch_timing)\n",
    "\n",
    "    return labels, us_images, warped_labels, viewable_labels, timing_info, pipeline.pcd_sampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire samples for demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "todo_dir = pthlib.joinpath(pthlib(this_folder), \"sample\")\n",
    "todo_dir.mkdir(exist_ok=True)\n",
    "\n",
    "if os.listdir(todo_dir) == []:\n",
    "    print(\"Downloading sample data\")\n",
    "    !wget -O /CT2US/sample/sample.zip \"https://www.dropbox.com/scl/fi/y44t2wu7eyg0t3fpknoxv/img.zip?rlkey=5uza6964xrrtffzfc7w977m3z&st=q6u2hzkh&dl=1\"\n",
    "    !unzip '/CT2US/sample/sample.zip' -d '/CT2US/sample'\n",
    "    !rm '/CT2US/sample/sample.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7LScpmFXvwKU"
   },
   "outputs": [],
   "source": [
    "# Set environment for Gradio\n",
    "os.environ[\"GRADIO_ALLOWED_PATHS\"] = this_folder\n",
    "\n",
    "def update_license(x):\n",
    "    global license\n",
    "    license = x\n",
    "\n",
    "with gr.Blocks() as ct_2_us:\n",
    "    # Create state objects for storing data\n",
    "    files = gr.State({})\n",
    "    us_list = gr.State({})\n",
    "    warped_list = gr.State({})\n",
    "    label_list = gr.State({})\n",
    "    pcdb_list = gr.State({})\n",
    "    # Store UI state to restore after processing\n",
    "    ui_state = gr.State({\n",
    "        \"method\": \"TotalSegmentator\",\n",
    "        \"use_roi\": True,\n",
    "        \"fast_mode\": False\n",
    "    })\n",
    "\n",
    "    pcd_method_obj = gr.State({})\n",
    "\n",
    "    img_idx = gr.State(0)\n",
    "    slice_idx = gr.State(0)\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            # Input configuration\n",
    "            gr.Markdown(\"Input Configuration\")\n",
    "            ct_imgs = gr.Files(\n",
    "                file_types=['.nii', '.gz'],\n",
    "                type='filepath',\n",
    "                label=\"Select CT images or preprocessed labelmaps\",\n",
    "                interactive=True,\n",
    "                file_count='multiple'\n",
    "            )\n",
    "\n",
    "            step_size = gr.Slider(\n",
    "                label=\"Slicing step interval\",\n",
    "                minimum=1,\n",
    "                maximum=20,\n",
    "                value=1,\n",
    "                step=1,\n",
    "                interactive=True\n",
    "            )\n",
    "\n",
    "            license_key = gr.Textbox(\n",
    "                label=\"License Key\",\n",
    "                placeholder=\"Enter your totalsegmentator license\",\n",
    "                value=license,\n",
    "                interactive=True\n",
    "            )\n",
    "\n",
    "\n",
    "            license_key.change(fn=update_license, inputs=[license_key], outputs=None)\n",
    "\n",
    "            # Advanced configuration (accessed via kwargs)\n",
    "            with gr.Accordion(\"Advanced Configuration\", open=False):\n",
    "                # Add ROI checkbox\n",
    "                use_roi = gr.Checkbox(\n",
    "                    label=\"Use Region of Interest (ROI)\",\n",
    "                    value=True,\n",
    "                    info=\"Enables ROI-based segmentation to focus on relevant anatomy\",\n",
    "                    interactive=True\n",
    "                )\n",
    "                \n",
    "                # Add Force CPU checkbox\n",
    "                force_cpu = gr.Checkbox(\n",
    "                    label=\"Force CPU Mode\",\n",
    "                    value=False,\n",
    "                    info=\"Force CPU usage even if GPU is available (for testing or debugging)\",\n",
    "                    interactive=True\n",
    "                )\n",
    "                \n",
    "                binary_dilation_iterations = gr.Slider(\n",
    "                    label=\"Binary Dilation Iterations\",\n",
    "                    minimum=0,\n",
    "                    maximum=5,\n",
    "                    value=2,\n",
    "                    step=1,\n",
    "                    interactive=True\n",
    "                )\n",
    "\n",
    "                binary_erosion_iterations = gr.Slider(\n",
    "                    label=\"Binary Erosion Iterations\",\n",
    "                    minimum=0,\n",
    "                    maximum=5,\n",
    "                    value=3,\n",
    "                    step=1,\n",
    "                    interactive=True\n",
    "                )\n",
    "\n",
    "                density_min = gr.Slider(\n",
    "                    label=\"Density Minimum\",\n",
    "                    minimum=-500,\n",
    "                    maximum=0,\n",
    "                    value=-200,\n",
    "                    step=10,\n",
    "                    interactive=True\n",
    "                )\n",
    "\n",
    "                density_max = gr.Slider(\n",
    "                    label=\"Density Maximum\",\n",
    "                    minimum=0,\n",
    "                    maximum=500,\n",
    "                    value=250,\n",
    "                    step=10,\n",
    "                    interactive=True\n",
    "                )\n",
    "\n",
    "                resize_size = gr.Slider(\n",
    "                    label=\"Resize Size\",\n",
    "                    minimum=256,\n",
    "                    maximum=512,\n",
    "                    value=380,\n",
    "                    step=8,\n",
    "                    interactive=True\n",
    "                )\n",
    "\n",
    "                crop_size = gr.Slider(\n",
    "                    label=\"Crop Size\",\n",
    "                    minimum=128,\n",
    "                    maximum=384,\n",
    "                    value=256,\n",
    "                    step=8,\n",
    "                    interactive=True\n",
    "                )\n",
    "\n",
    "                save_intermediates = gr.Checkbox(\n",
    "                    label=\"Save Intermediate Results\",\n",
    "                    value=False,\n",
    "                    interactive=True\n",
    "                )\n",
    "                \n",
    "                # Add Fast mode checkbox\n",
    "                fast_mode = gr.Checkbox(\n",
    "                    label=\"Use Fast Mode (3mm)\",\n",
    "                    value=False,\n",
    "                    info=\"Use faster 3mm resolution for segmentation (less accurate but quicker)\",\n",
    "                    interactive=True\n",
    "                )\n",
    "\n",
    "            with gr.Row():\n",
    "                btn = gr.Button(\"Segment CT\", variant=\"primary\")\n",
    "                bypass = gr.Button(\"Load labelmap\", variant=\"primary\")\n",
    "                reset = gr.Button(\"Reset\")\n",
    "\n",
    "            # Define reset handler\n",
    "            @gr.on([reset.click], inputs=None,\n",
    "                  outputs=[files, us_list, warped_list, label_list, pcdb_list])\n",
    "            def reset_all():\n",
    "                # Cleanup files\n",
    "                for f in glob.glob(str(label_dir / '*.nii.gz')):\n",
    "                    try:\n",
    "                        os.remove(f)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error removing {f}: {e}\")\n",
    "                        \n",
    "                for f in glob.glob(str(img_dir / '*.nii.gz')):\n",
    "                    try:\n",
    "                        os.remove(f)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error removing {f}: {e}\")\n",
    "\n",
    "                for f in glob.glob(str(pthlib(this_folder) / 'intermediates' / '*.nii.gz')):\n",
    "                    try:\n",
    "                        os.remove(f)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error removing {f}: {e}\")\n",
    "                        \n",
    "                for f in glob.glob(str(gen_dir / '*.glb')):\n",
    "                    try:\n",
    "                        os.remove(f)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error removing {f}: {e}\")\n",
    "                        \n",
    "                for f in glob.glob(f\"{str(us_dir)}/*\"):\n",
    "                    try:\n",
    "                        shutil.rmtree(f, ignore_errors=True)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error removing {f}: {e}\")\n",
    "                        \n",
    "                try:\n",
    "                    if os.path.exists(f\"{this_folder}/results.zip\"):\n",
    "                        os.remove(f\"{this_folder}/results.zip\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error removing results.zip: {e}\")\n",
    "                    \n",
    "                return {}, {}, {}, {}, {}\n",
    "\n",
    "            with gr.Row():\n",
    "                with gr.Column():\n",
    "                    # Sample selection for demo\n",
    "                    sample_in = gr.Dropdown(\n",
    "                        choices=[i+1 for i in range(len(glob.glob(f\"{this_folder}/sample/*.nii.gz\")))],\n",
    "                        label='Amount of samples to randomly select',\n",
    "                        info='Used for demo with no input',\n",
    "                        value=1\n",
    "                    )\n",
    "\n",
    "                    # Choose pipeline method\n",
    "                    available_methods = _factory.config.methods[\"segmentation\"].keys() - [PrelabeledBypass.name()]\n",
    "                    available_us = _factory.config.methods[\"rendering\"].keys() - [OptimizedLotusRenderer.name()]\n",
    "\n",
    "                    seg_method = gr.Radio(\n",
    "                        choices=available_methods,\n",
    "                        value=\"TotalSegmentator\",\n",
    "                        label=\"Segmentation method\",\n",
    "                        interactive=True\n",
    "                    )\n",
    "\n",
    "                    us_method = gr.Radio(\n",
    "                        choices=available_us,\n",
    "                        value=\"LOTUS\",\n",
    "                        label=\"US rendering method\",\n",
    "                        interactive=True\n",
    "                    )\n",
    "\n",
    "        with gr.Column(scale=2):\n",
    "            with gr.Tab(label='Pointcloud Settings', visible=False) as pcd_tab:\n",
    "                @gr.render(inputs=[step_size], triggers=[us_list.change])\n",
    "                def pcd_control(step):\n",
    "                    # Point cloud settings - only show if pipeline is available\n",
    "                    gr.Markdown(\"### Point Cloud Settings\")\n",
    "\n",
    "                    # Get tissue types with voxels\n",
    "                    label_counts = _pcd_method.get_label_counts()\n",
    "                    if label_counts and 0 in label_counts:\n",
    "                        available_labels = sorted(label_counts[0].keys())\n",
    "\n",
    "                        # Create sliders for each tissue type\n",
    "                        with gr.Row():\n",
    "                            with gr.Column():\n",
    "                                pcd_sliders = []\n",
    "                                for i, label in enumerate(available_labels):\n",
    "                                    if label in TISSUE_TYPES and TISSUE_TYPES[label] != \"Unused\":\n",
    "                                        # Get current point count\n",
    "                                        if i < len(_pcd_method.points_per_label):\n",
    "                                            current_value = _pcd_method.points_per_label[i]\n",
    "                                        else:\n",
    "                                            current_value = 0\n",
    "\n",
    "                                        # Calculate max points\n",
    "                                        max_points = min(label_counts[0].get(label, 0), 400000)\n",
    "\n",
    "                                        # Skip labels with no points\n",
    "                                        if max_points == 0:\n",
    "                                            continue\n",
    "\n",
    "                                        # Create slider\n",
    "                                        slider = gr.Slider(\n",
    "                                            label=f\"{TISSUE_TYPES[label]} Points\",\n",
    "                                            minimum=0,\n",
    "                                            maximum=max_points,\n",
    "                                            value=current_value,\n",
    "                                            step=1000,\n",
    "                                            interactive=True\n",
    "                                        )\n",
    "                                        pcd_sliders.append((label, slider))\n",
    "\n",
    "                                # Create update button\n",
    "                                update_pcd = gr.Button(\"Resample Pointcloud\")\n",
    "\n",
    "                                # Handle updates\n",
    "                                def update_point_cloud(x, y, *slider_values):\n",
    "                                    # Get current points per label\n",
    "                                    new_counts = _pcd_method.points_per_label.copy()\n",
    "\n",
    "                                    # Update with slider values\n",
    "                                    for (label, _), value in zip(pcd_sliders, slider_values):\n",
    "                                        if label < len(new_counts):\n",
    "                                            new_counts[label] = int(value)\n",
    "\n",
    "                                    # Update point cloud\n",
    "                                    _pcd_method.update_points_per_label(new_counts)\n",
    "\n",
    "                                    # Re-export\n",
    "                                    pcdb_new = _pcd_method.sample(x)\n",
    "\n",
    "                                    try:\n",
    "                                        # Make sure to use a safe value for the slice index\n",
    "                                        safe_slice = min(int(y * step), pcdb_new[2][2]-1) if len(pcdb_new) >= 3 and hasattr(pcdb_new[2], \"__len__\") and len(pcdb_new[2]) >= 3 else 0\n",
    "                                        _pcd_method.add_axis_pcd(pcdb_new, safe_slice).export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                                    except Exception as e:\n",
    "                                        print(f\"Error creating axis point cloud: {e}\")\n",
    "                                        # Create a fallback point cloud if there's an error\n",
    "                                        import trimesh as tri\n",
    "                                        fallback_pcd = tri.PointCloud([[0, 0, 0]], colors=[[255, 255, 255, 255]])\n",
    "                                        fallback_pcd.export(str(gen_dir / \"current_pcd.glb\"))\n",
    "\n",
    "                                    # Return the path to the new point cloud\n",
    "                                    return pcdb_new\n",
    "\n",
    "                                # Connect button to handler\n",
    "                                if pcd_sliders:\n",
    "                                    update_pcd.click(\n",
    "                                        fn=update_point_cloud,\n",
    "                                        inputs=[img_idx, slice_idx] + [s[1] for s in pcd_sliders],\n",
    "                                        outputs=pcdb_list\n",
    "                                    )\n",
    "\n",
    "\n",
    "            with gr.Tab(label='Preview'):\n",
    "                note = gr.Markdown(value=\"Generate US images first through the input tab\")\n",
    "\n",
    "                # Dynamic UI based on available data\n",
    "                @gr.render(inputs=[files, us_list, warped_list, label_list, step_size],\n",
    "                         triggers=[us_list.change])\n",
    "                def dynamic(fl, us, warped, ll, step):\n",
    "                    with gr.Column():\n",
    "                        if len(us) > 0:\n",
    "                            # Image selection\n",
    "                            dropdown = gr.Dropdown(\n",
    "                                choices=[(f, n) for n, f in fl.items()],\n",
    "                                label='Select image to preview',\n",
    "                                value=0\n",
    "                            )\n",
    "\n",
    "                            # Slice selection\n",
    "                            slider = gr.Slider(\n",
    "                                minimum=0,\n",
    "                                maximum=len(warped[0]) - 1,\n",
    "                                step=step,\n",
    "                                label='Slice selection',\n",
    "                                value=0\n",
    "                            )\n",
    "\n",
    "                            # Identity function for state updates\n",
    "                            iden = lambda x: x\n",
    "\n",
    "                            slider.release(fn=iden, inputs=[slider], outputs=[slice_idx])\n",
    "                            dropdown.select(fn=iden, inputs=[dropdown], outputs=[img_idx])\n",
    "\n",
    "                            # Results display\n",
    "                            with gr.Column():\n",
    "                                # Top row: US and label images\n",
    "                                with gr.Row():\n",
    "                                    base = gr.Image(\n",
    "                                        label='US slice',\n",
    "                                        value=np.asarray(us[img_idx.value][slice_idx.value], dtype=np.float32) if len(us) > 0 and len(us[0]) > 0 else np.zeros((256, 256), dtype=np.float32),\n",
    "                                        height=300\n",
    "                                    )\n",
    "\n",
    "                                    label_preview = gr.Image(\n",
    "                                        label='Label slice',\n",
    "                                        value=ll[img_idx.value][slice_idx.value] if len(ll) > 0 else None,\n",
    "                                        type='pil',\n",
    "                                        height=300\n",
    "                                    )\n",
    "\n",
    "                                # Bottom row: Annotation and 3D view\n",
    "                                with gr.Row():\n",
    "                                    comp = gr.AnnotatedImage(\n",
    "                                        value=(us[img_idx.value][slice_idx.value], warped[img_idx.value][slice_idx.value]),\n",
    "                                        height=300\n",
    "                                    )\n",
    "\n",
    "                                    volume_preview = gr.Model3D(\n",
    "                                        clear_color=(0, 0, 0, 1),\n",
    "                                        label=\"Label map view\",\n",
    "                                        value=str(gen_dir / \"current_pcd.glb\") if os.path.exists(str(gen_dir / \"current_pcd.glb\")) else None,\n",
    "                                        height=300\n",
    "                                    )\n",
    "\n",
    "                                pcdb_list.change(fn=lambda : str(gen_dir / \"current_pcd.glb\"), outputs=volume_preview)\n",
    "\n",
    "                                # Update function for image/slice selection\n",
    "                                def route(x, y, pcdb):\n",
    "                                        new_y = y if y < len(us[x]) else 0\n",
    "\n",
    "                                        b = us[x][new_y]\n",
    "                                        w = warped[x][new_y]\n",
    "                                        l = ll[x][new_y]\n",
    "\n",
    "                                        # adjust current slice highlighted\n",
    "                                        pcdb = _pcd_method.sample(x)\n",
    "\n",
    "                                        # Make sure to use a safe value for the slice index\n",
    "                                        safe_slice = min(int(y * step), pcdb[2][2]-1) if len(pcdb) >= 3 and hasattr(pcdb[2], \"__len__\") and len(pcdb[2]) >= 3 else 0\n",
    "                                        _pcd_method.add_axis_pcd(pcdb, safe_slice).export(str(gen_dir / \"current_pcd.glb\"))\n",
    "\n",
    "                                        # Calculate new slider value and ensure it's in range\n",
    "                                        new_slider = gr.Slider(\n",
    "                                            minimum=0,\n",
    "                                            maximum=len(warped[x]) - 1,\n",
    "                                            step=step,\n",
    "                                            label='Slice selection',\n",
    "                                            value=new_y\n",
    "                                        )\n",
    "\n",
    "                                        # Return updated UI components\n",
    "                                        return (b, w), b, l, str(gen_dir / \"current_pcd.glb\"), new_y, new_slider, pcdb\n",
    "\n",
    "                                def route_y(x, y, pcdb):\n",
    "                                        b = us[x][y]\n",
    "                                        w = warped[x][y]\n",
    "                                        l = ll[x][y]\n",
    "\n",
    "                                        # adjust current slice highlighted\n",
    "                                        try:\n",
    "                                            # Make sure to use a safe value for the slice index\n",
    "                                            safe_slice = min(int(y * step), pcdb[2][2]-1) if len(pcdb) >= 3 and hasattr(pcdb[2], \"__len__\") and len(pcdb[2]) >= 3 else 0\n",
    "                                            _pcd_method.add_axis_pcd(pcdb, safe_slice).export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"Error creating axis point cloud: {e}\")\n",
    "                                            # Create a fallback point cloud if there's an error\n",
    "                                            import trimesh as tri\n",
    "                                            fallback_pcd = tri.PointCloud([[0, 0, 0]], colors=[[255, 255, 255, 255]])\n",
    "                                            fallback_pcd.export(str(gen_dir / \"current_pcd.glb\"))\n",
    "\n",
    "                                        # Return updated UI components\n",
    "                                        return (b, w), b, l, str(gen_dir / \"current_pcd.glb\")\n",
    "\n",
    "                                # Connect route function to UI events\n",
    "                                gr.on(\n",
    "                                    triggers=[img_idx.change],\n",
    "                                    fn=route,\n",
    "                                    inputs=[img_idx, slice_idx, pcdb_list],\n",
    "                                    outputs=[comp, base, label_preview, volume_preview, slice_idx, slider, pcdb_list]\n",
    "                                )\n",
    "                                gr.on(\n",
    "                                    triggers=[slice_idx.change],\n",
    "                                    fn=route_y,\n",
    "                                    inputs=[img_idx, slice_idx, pcdb_list],\n",
    "                                    outputs=[comp, base, label_preview, volume_preview]\n",
    "                                )\n",
    "\n",
    "            with gr.Tab(label='Download'):\n",
    "                download = gr.DownloadButton(label=\"\", visible=False)\n",
    "\n",
    "                # Dynamic UI for download options\n",
    "                @gr.render(inputs=[files, us_list, warped_list, label_list, pcdb_list, step_size],\n",
    "                         triggers=[us_list.change])\n",
    "                def dynamic(fl, us, warped, ll, pcdb, step):\n",
    "                    # Create download button\n",
    "                    descr = gr.Markdown(label=\"This can be used to adjust contents of results.zip\")\n",
    "                    configs = gr.CheckboxGroup(\n",
    "                        choices=[\"Save labels\", \"Save US images\", \"Save intermediates\"],\n",
    "                        value=[\"Save labels\", \"Save US images\", \"Save intermediates\"],\n",
    "                        label=\"Options\",\n",
    "                        interactive=True\n",
    "                    )\n",
    "\n",
    "                    intermed_dir = pthlib(this_folder) / 'intermediates'\n",
    "\n",
    "                    rezip = gr.Button(\"Reassemble results.zip\")\n",
    "\n",
    "                    @gr.on(rezip.click, inputs=[configs], outputs=[download, descr])\n",
    "                    def rezip_files(save_configs):\n",
    "                        dest = pthlib(this_folder) / 'zip'\n",
    "                        os.mkdir(dest)\n",
    "                        files = glob.glob(f\"{this_folder}/zip/*\")\n",
    "                        for f in files:\n",
    "                            os.remove(f)\n",
    "\n",
    "                        if \"Save labels\" in save_configs:\n",
    "                            shutil.copytree(label_dir, dest / \"label\", dirs_exist_ok=True)\n",
    "\n",
    "                        if \"Save US images\" in save_configs:\n",
    "                            shutil.copytree(us_dir, dest / \"us\", dirs_exist_ok=True)\n",
    "\n",
    "                        if \"Save intermediates\" in save_configs:\n",
    "                            shutil.copytree(intermed_dir, dest / \"intermediate\", dirs_exist_ok=True)\n",
    "                        \n",
    "                        # Clean up if requested\n",
    "                        if \"Clean up after export\" in save_configs:\n",
    "                            for f in glob.glob(f\"{str(us_dir)}/*\"):\n",
    "                                shutil.rmtree(f, ignore_errors=True)\n",
    "                        \n",
    "                        shutil.make_archive(f\"{this_folder}/results\", 'zip', dest)\n",
    "\n",
    "                        return f\"{this_folder}/results.zip\", \"Results have been rezipped\"\n",
    "\n",
    "                # Function to hide pointcloud tab during processing\n",
    "                def hide_pcd_tab():\n",
    "                    return gr.Tab(label=\"Pointcloud Settings\", visible=False)\n",
    "\n",
    "                def start(ct, step, method, method_us, fl_s, us_s, warped_s, ll_s, pcdb_s, nr_samples,\n",
    "                         use_roi_enabled, force_cpu_enabled, \n",
    "                         binary_dilation_iters, binary_erosion_iters, \n",
    "                         dens_min, dens_max, resize, crop, save_int, fast_enabled, ui_state_val,\n",
    "                         progress=gr.Progress(track_tqdm=True)):\n",
    "                    # First ensure the working directory is completely clean\n",
    "                    try:\n",
    "                        # Clean img_dir first to avoid duplicates\n",
    "                        for f in glob.glob(str(img_dir / '*.nii.gz')):\n",
    "                            try:\n",
    "                                os.remove(f)\n",
    "                                print(f\"Cleaned up existing file: {f}\")\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error removing {f}: {e}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error during cleanup: {e}\")\n",
    "                        \n",
    "                    # Sample if no input\n",
    "                    if not ct:\n",
    "                        ct = glob.glob(f\"{this_folder}/sample/*.nii.gz\")\n",
    "                        ct = [f for f in ct]\n",
    "\n",
    "                    # Random sample if needed\n",
    "                    if len(ct) > nr_samples:\n",
    "                        ct = random.sample(ct, k=nr_samples)\n",
    "\n",
    "                    # Copy files to working directory - with unique names to avoid duplicates\n",
    "                    already_copied = set()\n",
    "                    for f in ct:\n",
    "                        try:\n",
    "                            # Get just the filename\n",
    "                            base_name = os.path.basename(f)\n",
    "                            \n",
    "                            # Skip if we've already copied this filename\n",
    "                            if base_name in already_copied:\n",
    "                                print(f\"Skipping duplicate file: {base_name}\")\n",
    "                                continue\n",
    "                                \n",
    "                            # Copy the file\n",
    "                            dest_path = str(img_dir / base_name)\n",
    "                            shutil.copyfile(f, dest_path)\n",
    "                            already_copied.add(base_name)\n",
    "                            print(f\"Copied {base_name} to working directory\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error copying file {f}: {e}\")\n",
    "                    \n",
    "                    # Auto-select the 3mm fast TotalSegmentator with ROI when CPU needs to be used\n",
    "                    # This happens when:\n",
    "                    # 1. force_cpu is enabled (explicit user choice)\n",
    "                    # 2. CUDA is not available on the system\n",
    "                    original_method = method\n",
    "                    original_roi = use_roi_enabled\n",
    "                    original_fast = fast_enabled\n",
    "                    \n",
    "                    need_cpu_mode = force_cpu_enabled or not torch.cuda.is_available()\n",
    "                    auto_adjusted = False\n",
    "                    \n",
    "                    if need_cpu_mode and not force_cpu_enabled:\n",
    "                        print(\"CPU-only environment detected. Auto-adjusting configuration for optimal performance.\")\n",
    "                        auto_adjusted = True\n",
    "                    \n",
    "                    # If CPU needs to be used (and it's not an explicit user choice with force_cpu), \n",
    "                    # auto-select optimized settings\n",
    "                    if need_cpu_mode and method != \"TotalSegmentator 3mm\":\n",
    "                        if not force_cpu_enabled:\n",
    "                            # Only auto-adjust if not explicitly forced to CPU by user\n",
    "                            method = \"TotalSegmentator 3mm\"\n",
    "                            use_roi_enabled = True\n",
    "                            fast_enabled = True\n",
    "                            print(f\"Auto-selected 3mm fast TotalSegmentator with ROI for CPU processing\")\n",
    "                            auto_adjusted = True\n",
    "                        else:\n",
    "                            # If user forced CPU but didn't select optimal settings, just suggest it\n",
    "                            if not (fast_enabled and use_roi_enabled and method == \"TotalSegmentator 3mm\"):\n",
    "                                print(\"TIP: For optimal CPU performance, consider using 'TotalSegmentator 3mm' with ROI and FAST mode enabled.\")\n",
    "\n",
    "                    # Display configuration settings\n",
    "                    if force_cpu_enabled:\n",
    "                        print(\"Force CPU mode enabled\")\n",
    "                    \n",
    "                    if use_roi_enabled:\n",
    "                        print(\"ROI feature enabled\")\n",
    "                        \n",
    "                    if fast_enabled:\n",
    "                        print(\"FAST mode (3mm) enabled\")\n",
    "\n",
    "                    # Organize parameters into component-specific configs\n",
    "                    # Common parameters for different components\n",
    "                    segmentation_config = {\n",
    "                        'binary_dilation_iterations': binary_dilation_iters,\n",
    "                        'binary_erosion_iterations': binary_erosion_iters,\n",
    "                        'density_min': dens_min,\n",
    "                        'density_max': dens_max,\n",
    "                        'use_roi': use_roi_enabled,\n",
    "                        'force_cpu': force_cpu_enabled,\n",
    "                        'fast': fast_enabled\n",
    "                    }\n",
    "\n",
    "                    rendering_config = {\n",
    "                        'binary_dilation_iterations': binary_dilation_iters,\n",
    "                        'binary_erosion_iterations': binary_erosion_iters,\n",
    "                        'density_min': dens_min,\n",
    "                        'density_max': dens_max,\n",
    "                        'resize_size': resize,\n",
    "                        'crop_size': crop,\n",
    "                        'force_cpu': force_cpu_enabled\n",
    "                    }\n",
    "\n",
    "                    # Process images using the pipeline with all configuration parameters\n",
    "                    labels, us_images, warped_labels, viewable_labels, timing_info, sampler = process_ct_images(\n",
    "                        ct_images=ct,\n",
    "                        step_size=step,\n",
    "                        segmentation_method=method,\n",
    "                        rendering_method=method_us,\n",
    "                        save_intermediates=save_int,\n",
    "                        force_cpu=force_cpu_enabled,\n",
    "                        segmentation_config=segmentation_config,\n",
    "                        rendering_config=rendering_config\n",
    "                    )\n",
    "\n",
    "                    # Get point cloud sampler for later adjustment\n",
    "                    global _pcd_method\n",
    "                    _pcd_method = sampler\n",
    "\n",
    "                    # Update state\n",
    "                    fl_s.update(enumerate(labels))\n",
    "                    us_s.update(enumerate(us_images))\n",
    "                    ll_s.update(enumerate(viewable_labels))\n",
    "                    warped_s.update(enumerate(warped_labels))\n",
    "\n",
    "                    # Sample point clouds and save initial 3D view\n",
    "                    pcdb_s = _pcd_method.sample(0)\n",
    "\n",
    "                    try:\n",
    "                        # Create initial view with slice 0\n",
    "                        _pcd_method.add_axis_pcd(pcdb_s, 0).export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating initial point cloud: {e}\")\n",
    "                        # Create a fallback point cloud if there's an error\n",
    "                        import trimesh as tri\n",
    "                        fallback_pcd = tri.PointCloud([[0, 0, 0]], colors=[[255, 255, 255, 255]])\n",
    "                        fallback_pcd.export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                    \n",
    "                    # Create message about any auto-adjustments that were made\n",
    "                    completion_message = \"Processing complete!\"\n",
    "                    if auto_adjusted:\n",
    "                        completion_message += \"\\nSettings were auto-adjusted for optimal CPU performance.\"\n",
    "                    \n",
    "                    # Store original vs auto-adjusted settings for UI restoration\n",
    "                    auto_adjust_info = {\n",
    "                        \"method\": {\"original\": original_method, \"adjusted\": method},\n",
    "                        \"use_roi\": {\"original\": original_roi, \"adjusted\": use_roi_enabled},\n",
    "                        \"fast\": {\"original\": original_fast, \"adjusted\": fast_enabled},\n",
    "                        \"auto_adjusted\": auto_adjusted\n",
    "                    }\n",
    "\n",
    "                    dest = pthlib(this_folder) / 'zip'\n",
    "                    shutil.copytree(label_dir, dest / \"label\", dirs_exist_ok=True)\n",
    "                    shutil.copytree(us_dir, dest / \"us\", dirs_exist_ok=True)\n",
    "                        \n",
    "                    shutil.make_archive(f\"{this_folder}/results\", 'zip', dest)\n",
    "\n",
    "                    # Return downloadable zip, updated states, and UI components to restore\n",
    "                    return (\n",
    "                        gr.DownloadButton(label=\"Download results as zip\", visible=True, value=f\"{this_folder}/results.zip\"),\n",
    "                        fl_s,\n",
    "                        us_s,\n",
    "                        warped_s,\n",
    "                        ll_s,\n",
    "                        pcdb_s,\n",
    "                        gr.Markdown(value=completion_message, height=30),\n",
    "                        auto_adjust_info\n",
    "                    )\n",
    "                \n",
    "                def bypass_start(label_list, step, method_us, fl_s, us_s, warped_s, ll_s, pcdb_s, nr_samples,\n",
    "                         use_roi_enabled, force_cpu_enabled, \n",
    "                         binary_dilation_iters, binary_erosion_iters, \n",
    "                         dens_min, dens_max, resize, crop, save_int, fast_enabled, ui_state_val,\n",
    "                         progress=gr.Progress(track_tqdm=True)):\n",
    "                    # First ensure the working directory is completely clean\n",
    "                    try:\n",
    "                        # Clean img_dir first to avoid duplicates\n",
    "                        for f in glob.glob(str(img_dir / '*.nii.gz')):\n",
    "                            try:\n",
    "                                os.remove(f)\n",
    "                                print(f\"Cleaned up existing file: {f}\")\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error removing {f}: {e}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error during cleanup: {e}\")\n",
    "                        \n",
    "                    # Sample if no input\n",
    "                    if not label_list:\n",
    "                        label_list = glob.glob(f\"{this_folder}/sample/prelabeled_*.nii.gz\")\n",
    "                        label_list = [f for f in label_list]\n",
    "\n",
    "                    # Random sample if needed\n",
    "                    if len(label_list) > nr_samples:\n",
    "                        label_list = random.sample(label_list, k=nr_samples)\n",
    "\n",
    "                    # Copy files to working directory - with unique names to avoid duplicates\n",
    "                    already_copied = set()\n",
    "                    for f in label_list:\n",
    "                        try:\n",
    "                            # Get just the filename\n",
    "                            base_name = os.path.basename(f)\n",
    "                            \n",
    "                            # Skip if we've already copied this filename\n",
    "                            if base_name in already_copied:\n",
    "                                print(f\"Skipping duplicate file: {base_name}\")\n",
    "                                continue\n",
    "                                \n",
    "                            # Copy the file\n",
    "                            dest_path = str(img_dir / base_name)\n",
    "                            shutil.copyfile(f, dest_path)\n",
    "                            already_copied.add(base_name)\n",
    "                            print(f\"Copied {base_name} to working directory\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error copying file {f}: {e}\")\n",
    "                    \n",
    "                    # Auto-select the 3mm fast TotalSegmentator with ROI when CPU needs to be used\n",
    "                    # This happens when:\n",
    "                    # 1. force_cpu is enabled (explicit user choice)\n",
    "                    # 2. CUDA is not available on the system\n",
    "                    original_method = \"PrelabeledBypass\"\n",
    "                    original_roi = use_roi_enabled\n",
    "                    original_fast = fast_enabled\n",
    "                    \n",
    "                    need_cpu_mode = force_cpu_enabled or not torch.cuda.is_available()\n",
    "                    auto_adjusted = False\n",
    "                    \n",
    "                    if need_cpu_mode and not force_cpu_enabled:\n",
    "                        print(\"CPU-only environment detected. Auto-adjusting configuration for optimal performance.\")\n",
    "                        auto_adjusted = True\n",
    "                    \n",
    "                    # If CPU needs to be used (and it's not an explicit user choice with force_cpu), \n",
    "                    # auto-select optimized settings\n",
    "                    if need_cpu_mode:\n",
    "                        if not force_cpu_enabled:\n",
    "                            # Only auto-adjust if not explicitly forced to CPU by user\n",
    "                            method = \"\"\n",
    "                            use_roi_enabled = True\n",
    "                            fast_enabled = True\n",
    "                            print(f\"Auto-selected 'PrelabeledBypass' for processing\")\n",
    "                            auto_adjusted = True\n",
    "                        else:\n",
    "                            # If user forced CPU but didn't select optimal settings, just suggest it\n",
    "                            if not (fast_enabled and use_roi_enabled and method == \"TotalSegmentator 3mm\"):\n",
    "                                print(\"TIP: For optimal CPU performance, consider using 'TotalSegmentator 3mm' with ROI and FAST mode enabled.\")\n",
    "\n",
    "                    # Display configuration settings\n",
    "                    if force_cpu_enabled:\n",
    "                        print(\"Force CPU mode enabled\")\n",
    "                    \n",
    "                    if use_roi_enabled:\n",
    "                        print(\"ROI feature enabled\")\n",
    "                        \n",
    "                    if fast_enabled:\n",
    "                        print(\"FAST mode (3mm) enabled\")\n",
    "\n",
    "                    # Organize parameters into component-specific configs\n",
    "                    # Common parameters for different components\n",
    "                    segmentation_config = {\n",
    "                        'binary_dilation_iterations': binary_dilation_iters,\n",
    "                        'binary_erosion_iterations': binary_erosion_iters,\n",
    "                        'density_min': dens_min,\n",
    "                        'density_max': dens_max,\n",
    "                        'use_roi': use_roi_enabled,\n",
    "                        'force_cpu': force_cpu_enabled,\n",
    "                        'fast': fast_enabled\n",
    "                    }\n",
    "\n",
    "                    rendering_config = {\n",
    "                        'binary_dilation_iterations': binary_dilation_iters,\n",
    "                        'binary_erosion_iterations': binary_erosion_iters,\n",
    "                        'density_min': dens_min,\n",
    "                        'density_max': dens_max,\n",
    "                        'resize_size': resize,\n",
    "                        'crop_size': crop,\n",
    "                        'force_cpu': force_cpu_enabled\n",
    "                    }\n",
    "\n",
    "                    # Process images using the pipeline with all configuration parameters\n",
    "                    labels, us_images, warped_labels, viewable_labels, timing_info, sampler = process_ct_images(\n",
    "                        ct_images=label_list,\n",
    "                        step_size=step,\n",
    "                        segmentation_method=\"PrelabeledBypass\",\n",
    "                        rendering_method=method_us,\n",
    "                        save_intermediates=save_int,\n",
    "                        force_cpu=force_cpu_enabled,\n",
    "                        segmentation_config=segmentation_config,\n",
    "                        rendering_config=rendering_config\n",
    "                    )\n",
    "\n",
    "                    # Get point cloud sampler for later adjustment\n",
    "                    global _pcd_method\n",
    "                    _pcd_method = sampler\n",
    "\n",
    "                    # Update state\n",
    "                    fl_s.update(enumerate(labels))\n",
    "                    us_s.update(enumerate(us_images))\n",
    "                    ll_s.update(enumerate(viewable_labels))\n",
    "                    warped_s.update(enumerate(warped_labels))\n",
    "\n",
    "                    # Sample point clouds and save initial 3D view\n",
    "                    pcdb_s = _pcd_method.sample(0)\n",
    "\n",
    "                    try:\n",
    "                        # Create initial view with slice 0\n",
    "                        _pcd_method.add_axis_pcd(pcdb_s, 0).export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error creating initial point cloud: {e}\")\n",
    "                        # Create a fallback point cloud if there's an error\n",
    "                        import trimesh as tri\n",
    "                        fallback_pcd = tri.PointCloud([[0, 0, 0]], colors=[[255, 255, 255, 255]])\n",
    "                        fallback_pcd.export(str(gen_dir / \"current_pcd.glb\"))\n",
    "                    \n",
    "                    # Create message about any auto-adjustments that were made\n",
    "                    completion_message = \"Processing complete!\"\n",
    "                    if auto_adjusted:\n",
    "                        completion_message += \"\\nSettings were auto-adjusted for optimal CPU performance.\"\n",
    "                    \n",
    "                    # Store original vs auto-adjusted settings for UI restoration\n",
    "                    auto_adjust_info = {\n",
    "                        \"method\": {\"original\": original_method, \"adjusted\": 'PrelabeledBypass'},\n",
    "                        \"use_roi\": {\"original\": original_roi, \"adjusted\": use_roi_enabled},\n",
    "                        \"fast\": {\"original\": original_fast, \"adjusted\": fast_enabled},\n",
    "                        \"auto_adjusted\": auto_adjusted\n",
    "                    }\n",
    "\n",
    "                    dest = pthlib(this_folder) / 'zip'\n",
    "                    shutil.copytree(label_dir, dest / \"label\", dirs_exist_ok=True)\n",
    "                    shutil.copytree(us_dir, dest / \"us\", dirs_exist_ok=True)\n",
    "                        \n",
    "                    shutil.make_archive(f\"{this_folder}/results\", 'zip', dest)\n",
    "\n",
    "                    # Return downloadable zip, updated states, and UI components to restore\n",
    "                    return (\n",
    "                        gr.DownloadButton(label=\"Download results as zip\", visible=True, value=f\"{this_folder}/results.zip\"),\n",
    "                        fl_s,\n",
    "                        us_s,\n",
    "                        warped_s,\n",
    "                        ll_s,\n",
    "                        pcdb_s,\n",
    "                        gr.Markdown(value=completion_message, height=30),\n",
    "                        auto_adjust_info\n",
    "                    )\n",
    "\n",
    "                def finalize(x):\n",
    "                    # Make the Pointcloud settings tab visible while preserving the note visibility\n",
    "                    # Do not modify the note component - return None to keep the current state\n",
    "                    return gr.Markdown(label=\"\", height=0, visible=False), gr.Tab(label=\"Pointcloud Settings\", visible=True)\n",
    "\n",
    "                # Store UI state before processing\n",
    "                def save_ui_state(method, use_roi_val, fast_mode_val):\n",
    "                    return {\"method\": method, \"use_roi\": use_roi_val, \"fast_mode\": fast_mode_val}\n",
    "                \n",
    "                # Restores UI to original settings after processing (except configs)\n",
    "                def restore_ui(ui_state_val, seg_method_val, use_roi_val, fast_mode_val):\n",
    "                    # Only restore if auto-adjustment was made\n",
    "                    if ui_state_val.get(\"auto_adjusted\", False):\n",
    "                        return (\n",
    "                            ui_state_val[\"method\"][\"original\"], \n",
    "                            ui_state_val[\"use_roi\"][\"original\"], \n",
    "                            ui_state_val[\"fast\"][\"original\"]\n",
    "                        )\n",
    "                    # Otherwise keep current values\n",
    "                    return seg_method_val, use_roi_val, fast_mode_val\n",
    "\n",
    "                # Connect generate button\n",
    "                btn.click(\n",
    "                    # Store UI state before processing\n",
    "                    fn=save_ui_state,\n",
    "                    inputs=[seg_method, use_roi, fast_mode],\n",
    "                    outputs=[ui_state]\n",
    "                ).success(\n",
    "                    fn=reset_all,\n",
    "                    inputs=None,\n",
    "                    outputs=[files, us_list, warped_list, label_list, pcdb_list]\n",
    "                ).success(\n",
    "                    # Hide pointcloud tab at start of processing\n",
    "                    fn=hide_pcd_tab,\n",
    "                    inputs=None,\n",
    "                    outputs=[pcd_tab]\n",
    "                ).success(\n",
    "                    fn=lambda x: gr.Markdown(label=\"Status\", value=\"Processing...\", height=80),\n",
    "                    inputs=btn,\n",
    "                    outputs=note\n",
    "                ).success(\n",
    "                    fn=start,\n",
    "                    inputs=[\n",
    "                        ct_imgs, step_size, seg_method, us_method, files, us_list, warped_list,\n",
    "                        label_list, pcdb_list, sample_in, use_roi, force_cpu, \n",
    "                        binary_dilation_iterations, binary_erosion_iterations, density_min, \n",
    "                        density_max, resize_size, crop_size, save_intermediates, \n",
    "                        fast_mode, ui_state\n",
    "                    ],\n",
    "                    outputs=[download, files, us_list, warped_list, label_list, pcdb_list, note, ui_state]\n",
    "                ).success(\n",
    "                    fn=finalize,\n",
    "                    inputs=btn,\n",
    "                    outputs=[note, pcd_tab]\n",
    "                ).success(\n",
    "                    # Restore UI to original state (if auto-adjusted)\n",
    "                    fn=restore_ui,\n",
    "                    inputs=[ui_state, seg_method, use_roi, fast_mode],\n",
    "                    outputs=[seg_method, use_roi, fast_mode]\n",
    "                )\n",
    "\n",
    "                                # Connect generate button\n",
    "                bypass.click(\n",
    "                    # Store UI state before processing\n",
    "                    fn=save_ui_state,\n",
    "                    inputs=[seg_method, use_roi, fast_mode],\n",
    "                    outputs=[ui_state]\n",
    "                ).success(\n",
    "                    fn=reset_all,\n",
    "                    inputs=None,\n",
    "                    outputs=[files, us_list, warped_list, label_list, pcdb_list]\n",
    "                ).success(\n",
    "                    # Hide pointcloud tab at start of processing\n",
    "                    fn=hide_pcd_tab,\n",
    "                    inputs=None,\n",
    "                    outputs=[pcd_tab]\n",
    "                ).success(\n",
    "                    fn=lambda x: gr.Markdown(label=\"Status\", value=\"Processing...\", height=80),\n",
    "                    inputs=bypass,\n",
    "                    outputs=note\n",
    "                ).success(\n",
    "                    fn=bypass_start,\n",
    "                    inputs=[\n",
    "                        ct_imgs, step_size, us_method, files, us_list, warped_list,\n",
    "                        label_list, pcdb_list, sample_in, use_roi, force_cpu, \n",
    "                        binary_dilation_iterations, binary_erosion_iterations, density_min, \n",
    "                        density_max, resize_size, crop_size, save_intermediates, \n",
    "                        fast_mode, ui_state\n",
    "                    ],\n",
    "                    outputs=[download, files, us_list, warped_list, label_list, pcdb_list, note, ui_state]\n",
    "                ).success(\n",
    "                    fn=finalize,\n",
    "                    inputs=bypass,\n",
    "                    outputs=[note, pcd_tab]\n",
    "                ).success(\n",
    "                    # Restore UI to original state (if auto-adjusted)\n",
    "                    fn=restore_ui,\n",
    "                    inputs=[ui_state, seg_method, use_roi, fast_mode],\n",
    "                    outputs=[seg_method, use_roi, fast_mode]\n",
    "                )\n",
    "\n",
    "# Launch the Gradio app\n",
    "ct_2_us.launch(debug=True, share=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "ct2us",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
